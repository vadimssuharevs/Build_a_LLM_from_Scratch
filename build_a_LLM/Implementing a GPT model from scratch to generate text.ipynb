{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a GPT model from scratch to generate text\n",
    "\n",
    "\n",
    "* Coding a GPT-like large language model (LLM)\n",
    "that can be trained to generate human-like text\n",
    "* Normalizing layer activations to stabilize neural\n",
    "network training\n",
    "* Adding shortcut connections in deep neural\n",
    "networks\n",
    "* Implementing transformer blocks to create GPT\n",
    "models of various sizes\n",
    "* Computing the number of parameters and\n",
    "storage requirements of GPT models\n",
    "* 12 transformers block in GPT2 124M\n",
    "* To put the scale of our project into perspective, consider the training of the 7 billion parameter Llama 2 model, a relatively popular openly available LLM. This model required 184,320 GPU hours on expensive A100 GPUs, processing 2 trillion tokens. At the time of writing, running an 8 Ã— A100 cloud server on AWS costs around $30 per hour. A rough estimate puts the total training cost of such an LLM at around $690,000 (calculated as 184,320 hours divided by 8, then multiplied by $30)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... it would take 355 years to train GPT-3 (175 billion) on a single V100 datacenter GPU\n",
    "and 665 years on a consumer RTX 8000 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257, # Vocabulary size\n",
    "\"context_length\": 1024, # Context length\n",
    "\"emb_dim\": 768, # Embedding dimension\n",
    "\"n_heads\": 12, # Number of attention heads\n",
    "\"n_layers\": 12, # Number of layers\n",
    "\"drop_rate\": 0.1, # Dropout rate\n",
    "\"qkv_bias\": False # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        \n",
    "        self.final_norm = DummyLayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "        torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "batch = []\n",
    "txt1 = 'Every effort moves you'\n",
    "txt2 = 'Every day holds a'\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model 124M\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing activations with layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.4091, 0.6587, 0.3914, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1902, 0.3182, 0.6486, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_sample = torch.rand(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_sample)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[0.2432],\n",
      "        [0.1928]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[0.0799],\n",
      "        [0.0670]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print('Mean: \\n', mean)\n",
    "print('Variance: \\n', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs: \n",
      " tensor([[-0.8603, -0.8603,  0.5869,  1.4698,  0.5242, -0.8603],\n",
      "        [-0.7450, -0.7450, -0.0102,  0.4844,  1.7608, -0.7450]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[0.0000e+00],\n",
      "        [9.9341e-09]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print('Normalized layer outputs: \\n', out_norm)\n",
    "print('Mean:\\n', mean)\n",
    "print('Variance:\\n', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print('Mean:\\n', mean)\n",
    "print('Variance:\\n', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer normalization class \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[     0.0000],\n",
      "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.9998],\n",
      "        [0.9999]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_sample)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing a feed forward network with GELU activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELU activation function\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward nn module\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], cfg['emb_dim'] * 4),\n",
    "            GELU(),\n",
    "            nn.Linear(cfg['emb_dim'] * 4, cfg['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shortcut Connection (Skip or Residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN to illustrate shortcut connections\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),\n",
    "                          GELU())\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = loss_fn(output, target)\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name and param.grad is not None:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explanation of the Results\\n\\nThe results show how **shortcut connections** (or their absence) affect the gradients during training.\\n\\nResults without shortcut (model without shortcut):\\n- The gradients for the layer weights are **smaller** with minimal variance across layers. \\n- This suggests that the model updates weights more slowly and in a more stable manner, which is typical for standard neural networks without shortcut connections.\\n\\nResults with shortcut (model with shortcut):\\n- The gradients are significantly **larger**, ranging from 0.2 to 1.3 for different layers.\\n- This is because **shortcut connections** allow for **easier information flow** between layers, enhancing the **trainability** of the model.\\n- Larger gradients help the network update weights faster, especially in deep networks.\\n\\nConclusion:\\n- **Without shortcut:** Smaller gradients, possibly slower learning.\\n- **With shortcut:** Larger gradients, leading to faster training and better information flow in deep networks.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Explanation of the Results\n",
    "\n",
    "The results show how **shortcut connections** (or their absence) affect the gradients during training.\n",
    "\n",
    "Results without shortcut (model without shortcut):\n",
    "- The gradients for the layer weights are **smaller** with minimal variance across layers. \n",
    "- This suggests that the model updates weights more slowly and in a more stable manner, which is typical for standard neural networks without shortcut connections.\n",
    "\n",
    "Results with shortcut (model with shortcut):\n",
    "- The gradients are significantly **larger**, ranging from 0.2 to 1.3 for different layers.\n",
    "- This is because **shortcut connections** allow for **easier information flow** between layers, enhancing the **trainability** of the model.\n",
    "- Larger gradients help the network update weights faster, especially in deep networks.\n",
    "\n",
    "Conclusion:\n",
    "- **Without shortcut:** Smaller gradients, possibly slower learning.\n",
    "- **With shortcut:** Larger gradients, leading to faster training and better information flow in deep networks.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connecting attention and linear layers in a transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements multi-head self-attention efficiently. \n",
    "    Instead of processing each attention head separately, it uses a single large weight matrix \n",
    "    and splits the outputs into multiple heads. This allows for parallel computation, \n",
    "    improving speed and reducing memory usage.\n",
    "\n",
    "    Key features:\n",
    "    - Uses a single set of weights for query, key, and value projections.\n",
    "    - Splits the projected values into multiple attention heads.\n",
    "    - Applies causal masking to prevent information leakage from future tokens.\n",
    "    - Computes attention in parallel across all heads.\n",
    "    - Uses an output projection layer to merge information from all heads.\n",
    "\n",
    "    This implementation is more efficient than stacking multiple single-head attention layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_in, d_out, \n",
    "                 context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            'd_out must be divisible by num_heads'\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.d_head)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.d_head)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.d_head)\n",
    "\n",
    "\n",
    "        \n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        \n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer block component of GPT\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias'])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 5, 768])\n",
      "Output shape: torch.Size([2, 5, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 5, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coding the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "vocabulary size of the tokenizer: 50257\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)\n",
    "print(f'vocabulary size of the tokenizer: {50257}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "# number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "# trainable parameters\n",
    "total_params_gpt2 = (\n",
    "total_params - sum(p.numel()\n",
    "for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of trainable parameters \"\n",
    "f\"considering weight tying: {total_params_gpt2:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# model size\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates a simple implementation of a generative loop for a lan-\n",
    "guage model using PyTorch. It iterates for a specified number of new tokens to be\n",
    "generated, crops the current context to fit the modelâ€™s maximum context size, com-\n",
    "putes predictions, and then selects the next token based on the highest probability\n",
    "prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    '''\n",
    "    Generates text using a GPT model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The GPT model.\n",
    "    - idx: The current token sequence (batch, n_tokens).\n",
    "    - max_new_tokens: Number of new tokens to generate.\n",
    "    - context_size: Maximum number of tokens used as context.\n",
    "\n",
    "    Returns:\n",
    "    - Updated idx with newly generated tokens.\n",
    "    '''\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Keep only the last context_size tokens\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)  # Get model predictions\n",
    "\n",
    "        logits = logits[:, -1, :]  # Focus on the last time step\n",
    "        probas = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # Select the most probable token\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # Append the new token\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n",
      "\n",
      "! The model is unable to produce coherent text is that we havenâ€™t trained it yet.\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text + \"\\n\")\n",
    "print('! The model is unable to produce coherent text is that we havenâ€™t trained it yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Layer normalization** stabilizes training by ensuring that each layerâ€™s outputs have a consistent mean and variance.  \n",
    "- **Shortcut connections** skip one or more layers, allowing outputs to be fed directly to deeper layers. This helps mitigate the **vanishing gradient problem**, especially in deep neural networks like LLMs.  \n",
    "- **Transformer blocks** are the core of GPT models, combining **masked multi-head attention** with **fully connected feed-forward networks** that use the **GELU activation function**.  \n",
    "- **GPT models** are LLMs composed of multiple **repeated transformer blocks**, containing **millions to billions of parameters**.  \n",
    "- **GPT models come in different sizes**, such as **124M, 345M, 762M, and 1,542M parameters**, all of which can be implemented using the same `GPTModel` Python class.  \n",
    "- **Text generation in GPT models** involves decoding output tensors into human-readable text by **predicting one token at a time** based on a given input context.  \n",
    "- **Without training, a GPT model generates incoherent text**, highlighting the necessity of training for coherent text generation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256,  # original: 1024\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Converts a text string into a tensor of token IDs using the specified tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    - text: The input string to tokenize.\n",
    "    - tokenizer: The tokenizer used to encode the text.\n",
    "\n",
    "    Returns:\n",
    "    - A PyTorch tensor containing the token IDs with an added batch dimension.\n",
    "    \"\"\"\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    \"\"\"\n",
    "    Converts a tensor of token IDs back into a human-readable text string.\n",
    "\n",
    "    Parameters:\n",
    "    - token_ids: A tensor containing token IDs.\n",
    "    - tokenizer: The tokenizer used to decode the token IDs.\n",
    "\n",
    "    Returns:\n",
    "    - A decoded text string.\n",
    "    \"\"\"\n",
    "    flat = token_ids.squeeze(0)  # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# Define the initial text input\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Generate new token IDs using the GPT model\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# Convert generated token IDs back to text and print\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],  # [\"every effort moves\",\n",
    "                          [40, 1107, 588]])  # \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                       [1107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print('Characters:', total_characters)\n",
    "print('Tokens:', total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class GPTDatasetV1:\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokens = tokenizer.encode(txt)\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        self.samples = self._create_samples()\n",
    "\n",
    "    def _create_samples(self):\n",
    "        samples = []\n",
    "        for i in range(0, len(self.tokens) - self.max_length, self.stride):\n",
    "            input_tokens = self.tokens[i:i + self.max_length]\n",
    "            target_tokens = self.tokens[i + 1:i + self.max_length + 1]\n",
    "            samples.append((input_tokens, target_tokens))  # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ (Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ, Ñ†ÐµÐ»ÑŒ)\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_tokens, target_tokens = self.samples[idx]\n",
    "        return torch.tensor(input_tokens, dtype=torch.long), torch.tensor(target_tokens, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)  # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ batch Ð½Ð° Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ñ†ÐµÐ»Ð¸\n",
    "    inputs = torch.stack(inputs)  # ÐŸÑ€ÐµÐ²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð² Ð±Ð°Ñ‚Ñ‡ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ð¾Ð²\n",
    "    targets = torch.stack(targets)\n",
    "    return inputs, targets\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")  # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)  # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn  # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ collate_fn Ð´Ð»Ñ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ‹\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583690219456\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Process in PyTorch\n",
    "\n",
    "1. **Loop over epochs** â€“ Full pass through the dataset.\n",
    "2. **Loop over batches** â€“ Split data into mini-batches.\n",
    "3. **Zero gradients** â€“ Reset gradients to prevent accumulation:\n",
    "   ```python\n",
    "   optimizer.zero_grad()\n",
    "   ```\n",
    "4. **Compute loss** â€“ Forward pass and loss calculation:\n",
    "   ```python\n",
    "   outputs = model(input_batch)\n",
    "   loss = loss_function(outputs, target_batch)\n",
    "   ```\n",
    "5. **Backpropagation** â€“ Compute gradients:\n",
    "   ```python\n",
    "   loss.backward()\n",
    "   ```\n",
    "6. **Update weights** â€“ Adjust model parameters:\n",
    "   ```python\n",
    "   optimizer.step()\n",
    "   ```\n",
    "7. **Print losses** â€“ Monitor training and validation loss.\n",
    "8. **Generate text (optional)** â€“ Inspect model output:\n",
    "   ```python\n",
    "   sample_text = generate_text(model, tokenizer, prompt=\"AI is\")\n",
    "   print(sample_text)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main function for pretraining LLMs\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                        eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    for epoch in range(num_epochs):  # Main training loop\n",
    "        model.train()  \n",
    "        \n",
    "        for input_batch, target_batch in train_loader:  # Iterate over batches\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update model weights\n",
    "\n",
    "            tokens_seen += input_batch.numel()  # Track number of processed tokens\n",
    "            global_step += 1  \n",
    "\n",
    "            if global_step % eval_freq == 0:  # Evaluate model at specified intervals\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                \n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "                generate_and_print_sample(model, tokenizer, device, start_context)  # Generate sample text\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # Set the model to evaluation mode (disables dropout, batch norm updates)\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation to save memory and speed up evaluation\n",
    "        train_loss = calc_loss_loader(train_loader, model, device,      num_batches=eval_iter)  # Compute train loss\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)  # Compute validation loss\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return train_loss, val_loss  # Return computed losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, batch norm updates)\n",
    "\n",
    "    context_size = model.pos_emb.weight.shape[0]  # Get the context size from positional embeddings\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)  # Encode input text and move to device\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking for efficiency\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, \n",
    "            max_new_tokens=50, context_size=context_size  # Generate up to 50 new tokens\n",
    "        )\n",
    "\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)  # Convert token IDs back to text\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Print output with newlines replaced for readability\n",
    "\n",
    "    model.train()  # Switch model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, the to the to the.                                           \n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Every effort moves you, and, and the of the of the of the of the of the of the of the of the of the of the of the of the the of the the of the of the of the of the of the of the of the of the of\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you his \" to the picture.  \"I, and I had been, and, and I had been, and I had been, and I had the his--I, and I had been, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Every effort moves you of the to the picture.                      \"I\"I me his\"I my\"I\"I\"I and my\"I\"I me\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you, as,,,,,,, as,, as.                      \"--and it's the,,,,,,,,\n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Every effort moves you know it was not to the picture--I he was a little the last word.     \"I, and. \"I, and I had been at my dear and I felt a little a little of the picture. \n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know the fact, and I felt he was to the fact had the last word. Gisburn's an!                           \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Every effort moves you know it was not that, and he was--I had a little of a little: \"Yes, and up, I had been to the donkey, I had always to have him. \"--and, and down, and he was his\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was not that, on the picture--I told Mrs.                                    \n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Every effort moves you know,\" was one of the picture for nothing--I had a little of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"There were, I had\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, and. Gisburn, and I had been at my elbow and as I had been the \"strongest,\" she was\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, the moment--as Jack himself, my elbow and as I turned, my eye fell on a small picture\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # Set random seed for reproducibility\n",
    "model = GPTModel(GPT_CONFIG_124M)  # Initialize the model with the given configuration\n",
    "model.to(device)  # Move the model to the appropriate device (CPU or GPU)\n",
    "\n",
    "# Initialize the optimizer (AdamW with learning rate and weight decay)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004,  # Learning rate\n",
    "    weight_decay=0.1  # Weight decay (L2 regularization)\n",
    ")\n",
    "\n",
    "num_epochs = 10  # Number of epochs for training\n",
    "\n",
    "# Train the model using the simple training loop\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,  # Model, data loaders, optimizer, device\n",
    "    num_epochs=num_epochs,  # Number of epochs\n",
    "    eval_freq=5,  # Frequency of evaluation during training (every 5 steps)\n",
    "    eval_iter=5,  # Number of iterations for evaluation\n",
    "    start_context=\"Every effort moves you\",  # Initial text for text generation during evaluation\n",
    "    tokenizer=tokenizer  # Tokenizer used for processing text\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Function to plot training and validation losses\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    # Create a figure and axis for plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot the training and validation losses against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    \n",
    "    # Set the x and y axis labels\n",
    "    ax1.set_xlabel(\"Epochs\")  # X-axis label for epochs\n",
    "    ax1.set_ylabel(\"Loss\")  # Y-axis label for loss\n",
    "\n",
    "    # Display a legend for the plot\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    \n",
    "    # Ensure that the x-axis ticks are integer values\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # Create a second x-axis (top) for tokens seen\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    # Plot an invisible line to link the top x-axis (tokens_seen) to the training losses\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # alpha=0 makes the line invisible\n",
    "\n",
    "    # Set the label for the second x-axis (tokens seen)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    # Automatically adjust the layout to avoid overlapping labels and elements\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Create a tensor for epochs ranging from 0 to num_epochs with the same length as train_losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "\n",
    "# Call the plot_losses function to plot the training and validation losses\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting training and validation loss plot is shown in figure 5.12. As we can see, both the training and validation losses start to improve for the first epoch. However, the losses start to diverge past the second epoch. This divergence and the fact that the validation loss is much larger than the training loss indicate that the model is overfitting to the training data. We can confirm that the model memorizes the training data verbatim by searching for the generated text snippets, such as quite insensible to the irony in the â€œThe Verdictâ€ text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")  # Move the model to CPU\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")  # Initialize the tokenizer\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "    for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the softmax_with_temperature function\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    \"\"\"\n",
    "    Applies softmax to logits with temperature scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - logits: Tensor of logits.\n",
    "    - temperature: Temperature value for scaling.\n",
    "\n",
    "    Returns:\n",
    "    - Scaled probabilities after applying softmax.\n",
    "    \"\"\"\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "                 for T in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "\n",
    "# Ensure next_token_logits is a tensor\n",
    "if isinstance(next_token_logits, list):\n",
    "    next_token_logits = torch.tensor(next_token_logits)\n",
    "\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified logits: tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where values lower than the smallest top-k logit are set to -inf\n",
    "new_logits = torch.where(\n",
    "    next_token_logits < top_logits[-1],  # Condition: if value < smallest top-k logit\n",
    "    torch.full_like(next_token_logits, float('-inf')),  # Assign -inf\n",
    "    next_token_logits  # Otherwise, keep original value\n",
    ")\n",
    "\n",
    "print(\"Modified logits:\", new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Limit the context to the last tokens\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)  # Get model predictions\n",
    "            logits = logits[:, -1, :]  # Focus on the last timestep logits\n",
    "        \n",
    "        # Apply top-k filtering\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, \n",
    "                                 torch.full_like(logits, float('-inf')), \n",
    "                                 logits)\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # Sample from probabilities\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # Greedy selection\n",
    "        \n",
    "        # Stop generation if end-of-sequence token is reached\n",
    "        if eos_id is not None and (idx_next == eos_id).all():\n",
    "            break\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # Append the new token to the sequence\n",
    "    \n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x1275758b0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 17:03:55.503121: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                        \"Right: {right.shape}\"\n",
    ")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"]) [\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"]) [\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary\n",
    "\n",
    "- When LLMs generate text, they output one token at a time.  \n",
    "- By default, the next token is generated by converting the model outputs into probability scores and selecting the token from the vocabulary that corresponds to the highest probability score, which is known as â€œgreedy decoding.â€  \n",
    "- Using probabilistic sampling and temperature scaling, we can influence the diversity and coherence of the generated text.  \n",
    "- Training and validation set losses can be used to gauge the quality of text generated by LLM during training.  \n",
    "\n",
    "##### Pretraining on Unlabeled Data  \n",
    "\n",
    "- Pretraining an LLM involves changing its weights to minimize the training loss.  \n",
    "- The training loop for LLMs itself is a standard procedure in deep learning, using a conventional cross-entropy loss and AdamW optimizer.  \n",
    "- Pretraining an LLM on a large text corpus is time- and resource-intensive, so we can load openly available weights as an alternative to pretraining the model on a large dataset ourselves.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will Ã¼ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a balanced dataset\n",
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
    "    num_spam, random_state=123\n",
    "    )\n",
    "\n",
    "    balanced_df = pd.concat([\n",
    "    ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset \n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    \n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a Pytorch Dataset class\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Pretokenizes texts\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        # Truncates sequences if they are longer than max_length\n",
    "        self.encoded_texts = [\n",
    "            encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "        \n",
    "        # Pads sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    "csv_file=\"train.csv\",\n",
    "max_length=None,\n",
    "tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PyTorch data loadersfrom torch.utils.data import DataLoader\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n",
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)\n",
    "\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a pretrained GPT model\n",
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "model=model,\n",
    "idx=text_to_token_ids(text_1, tokenizer),\n",
    "max_new_tokens=15,\n",
    "context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "# letâ€™s see whether the model already classifies spam messages by prompting it with instructions\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "model=model,\n",
    "idx=text_to_token_ids(text_2, tokenizer),\n",
    "max_new_tokens=23,\n",
    "context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a classification layer\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], \n",
    "                                 out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "\tmodel.eval()\n",
    "\tcorrect_predictions, num_examples = 0, 0\n",
    "\tif num_batches is None:\n",
    "\t\tnum_batches = len(data_loader)\n",
    "\telse:\n",
    "\t\tnum_batches = min(num_batches, len(data_loader))\n",
    "\tfor i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "\t\tif i < num_batches:\n",
    "\t\t\tinput_batch = input_batch.to(device)\n",
    "\t\t\ttarget_batch = target_batch.to(device)\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tlogits = model(input_batch)[:, -1, :]\n",
    "\t\t\t\tpredicted_labels = torch.argmax(logits, dim=-1)\n",
    "\t\t\t\tnum_examples += predicted_labels.shape[0]\n",
    "\t\t\t\tcorrect_predictions += (predicted_labels == target_batch).sum().item()\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\treturn correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "\tinput_batch = input_batch.to(device)\n",
    "\ttarget_batch = target_batch.to(device)\n",
    "\tlogits = model(input_batch)[:, -1, :]  # Logits of the last output token\n",
    "\tloss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the classification loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "\ttotal_loss = 0.0\n",
    "\tif len(data_loader) == 0:\n",
    "\t\treturn float(\"nan\")\n",
    "\telif num_batches is None:\n",
    "\t\tnum_batches = len(data_loader)\n",
    "\telse:\n",
    "\t\tnum_batches = min(num_batches, len(data_loader))\n",
    "\t\n",
    "\tfor i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "\t\tif i < num_batches:\n",
    "\t\t\tloss = calc_loss_batch(\n",
    "\t\t\t\tinput_batch, target_batch, model, device\n",
    "\t\t\t)\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\treturn total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # Disables gradient tracking for efficiency because we are not training yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine-tuning the model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter\n",
    "):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Sets model to training mode\n",
    "\n",
    "        # Resets loss gradients\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Clears gradients from the previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # Calculates loss\n",
    "            loss.backward()  # Calculates loss gradients\n",
    "            optimizer.step()  # Updates model weights using loss gradients\n",
    "\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\")\n",
    "\n",
    "                train_accuracy = calc_accuracy_loader(\n",
    "                    train_loader, model, device, num_batches=eval_iter\n",
    "                )\n",
    "                val_accuracy = calc_accuracy_loader(\n",
    "                    val_loader, model, device, num_batches=eval_iter\n",
    "                )\n",
    "                print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "                print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "                train_accs.append(train_accuracy)\n",
    "                val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The evaluate_model function is identical to the one we used for pretraining\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.884, Val loss 2.596\n",
      "Training accuracy: 50.00% | Validation accuracy: 50.00%\n",
      "Ep 1 (Step 000050): Train loss 0.378, Val loss 0.190\n",
      "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
      "Ep 1 (Step 000100): Train loss 0.479, Val loss 0.501\n",
      "Training accuracy: 87.50% | Validation accuracy: 80.00%\n",
      "Ep 2 (Step 000150): Train loss 0.191, Val loss 0.076\n",
      "Training accuracy: 92.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000200): Train loss 0.109, Val loss 0.112\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000250): Train loss 0.023, Val loss 0.036\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.137, Val loss 0.042\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000350): Train loss 0.004, Val loss 0.095\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 4 (Step 000400): Train loss 0.003, Val loss 0.096\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 4 (Step 000450): Train loss 0.001, Val loss 0.020\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 4 (Step 000500): Train loss 0.013, Val loss 0.105\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.000, Val loss 0.032\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000600): Train loss 0.000, Val loss 0.048\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 60.64 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
    "train_classifier_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                        num_epochs=num_epochs, eval_freq=50,\n",
    "                        eval_iter=5)\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    \"\"\"\n",
    "    Plots training and validation values against epochs and examples seen.\n",
    "\n",
    "    Parameters:\n",
    "    - epochs_seen: Tensor or list of epochs.\n",
    "    - examples_seen: Tensor or list of examples seen.\n",
    "    - train_values: List of training values (e.g., losses or accuracies).\n",
    "    - val_values: List of validation values (e.g., losses or accuracies).\n",
    "    - label: Label for the y-axis and legend (default is \"loss\").\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation values against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    # Adjust layout to make room\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate tensors for epochs and examples seen\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "# Plot the values\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
    "            label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00%\n",
      "Validation accuracy: 98.66%\n",
      "Test accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    \"\"\"\n",
    "    Classifies a given text as 'spam' or 'not spam' using the provided model.\n",
    "\n",
    "    Parameters:\n",
    "    - text: The input text to classify.\n",
    "    - model: The trained classification model.\n",
    "    - tokenizer: The tokenizer to encode the text.\n",
    "    - device: The device (CPU or GPU) to run the model on.\n",
    "    - max_length: The maximum length of the input sequence (optional).\n",
    "    - pad_token_id: The token ID used for padding (default is 50256).\n",
    "\n",
    "    Returns:\n",
    "    - 'spam' if the predicted label is 1, otherwise 'not spam'.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    # Truncate sequences if they are too long\n",
    "    if max_length is None:\n",
    "        max_length = supported_context_length\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the maximum length\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\")\n",
    "\n",
    "print(classify_review(\n",
    "text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- There are different strategies for fine-tuning LLMs, including classification fine-tuning and instruction fine-tuning.  \n",
    "- Classification fine-tuning involves replacing the output layer of an LLM with a small classification layer.  \n",
    "- In the case of classifying text messages as â€œspamâ€ or â€œnot spam,â€ the new classification layer consists of only two output nodes. Previously, the number of output nodes was equal to the number of unique tokens in the vocabulary (i.e., 50,256).  \n",
    "- Instead of predicting the next token in the text as in pretraining, classification fine-tuning trains the model to output a correct class labelâ€”for example, â€œspamâ€ or â€œnot spam.â€  \n",
    "- The model input for fine-tuning is text converted into token IDs, similar to pretraining.  \n",
    "- Before fine-tuning an LLM, we load the pretrained model as a base model.  \n",
    "- Evaluating a classification model involves calculating the classification accuracy (the fraction or percentage of correct predictions).  \n",
    "- Fine-tuning a classification model uses the same cross-entropy loss function as when pretraining the LLM.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning to follow instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    data = json.loads(text_data)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the prompt formatting function \n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "    f\"Below is an instruction that describes a task. \"\n",
    "    f\"Write a response that appropriately completes the request.\"\n",
    "    f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "        )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Partitioning the dataset\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        # Pretokenizes texts\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    # Finds the longest sequence in the batch\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst = []\n",
    "    \n",
    "    for item in batch:\n",
    "        # Pads and prepares inputs\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    "    )\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        # Padding the sequence\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        \n",
    "        # Truncate the last token for inputs\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        \n",
    "        # Shift +1 to the right for targets\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "# Example usage\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a custom batch collate function\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        \n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "    [-0.5, 1.5]]\n",
    "    )\n",
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "    \n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "    [-0.5, 1.5],\n",
    "    [-0.5, 1.5]]\n",
    "    )\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():\n",
    "# device = torch.device(\"mps\")\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "custom_collate_fn,\n",
    "device=device,\n",
    "allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the data loaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    "    )\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    "    )\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 27.0kiB/s]\n",
      "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:00<00:00, 1.20MiB/s]\n",
      "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91.0/91.0 [00:00<00:00, 50.1kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42G/1.42G [05:49<00:00, 4.06MiB/s] \n",
      "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.4k/10.4k [00:00<00:00, 6.98MiB/s]\n",
      "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 927k/927k [00:01<00:00, 776kiB/s] \n",
      "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 505kiB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reuse the existing imports and definitions for GPTModel and load_weights_into_gpt\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,  # Dropout rate\n",
    "    \"qkv_bias\": True  # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "# Reuse the download_and_load_gpt2 function from cell index 18\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "# Reuse the GPTModel and load_weights_into_gpt from cell index 18\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    "    )\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    \n",
    "    # Ensure input and target tensors have the same batch size\n",
    "    if input_batch.shape[0] != target_batch.shape[0]:\n",
    "        raise ValueError(f\"Input batch size ({input_batch.shape[0]}) does not match target batch size ({target_batch.shape[0]}).\")\n",
    "    \n",
    "    logits = model(input_batch)[:, :-1, :]  # Logits for all tokens except the last\n",
    "    target_batch = target_batch[:, 1:]  # Shift target tokens to align with logits\n",
    "    \n",
    "    # Flatten logits and target tensors for cross-entropy loss\n",
    "    logits = logits.reshape(-1, logits.size(-1))\n",
    "    target_batch = target_batch.reshape(-1)\n",
    "    \n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch, ignore_index=-100)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 9.561110305786134\n",
      "Validation loss: 9.673491287231446\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    "    )\n",
    "    print(\"Training loss:\", train_loss)\n",
    "    print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 7.396, Val loss 7.392\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.  ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### \n",
      "Ep 1 (Step 000005): Train loss 4.410, Val loss 4.403\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ###: : : : : : : : : : : : : : : : : : : : : : : :\n",
      "Ep 1 (Step 000010): Train loss 2.800, Val loss 2.879\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000015): Train loss 2.425, Val loss 2.514\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The. chef. the. meal. every. day<|endoftext|>The following is a that describes task Write that completes request ###: the. the. the. the. the. the.<|endoftext|>: The History of the. the.\n",
      "Ep 1 (Step 000020): Train loss 2.171, Val loss 2.308\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The. '. the........<|endoftext|>The following is a that describes task Write that that that completes sentence ###:The. '. the.......<|endoftext|>.  .\n",
      "Ep 1 (Step 000025): Train loss 2.112, Val loss 2.195\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The. '. the......<|endoftext|>: The. '. the. '.<|endoftext|>: The. '. the. '.<|endoftext|>: The. '. the.  :...  \n",
      "Ep 1 (Step 000030): Train loss 1.893, Val loss 2.087\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The sentence 'The the the the the the the the the the the the the the the the the the<|endoftext|>: The History of the the of the<|endoftext|>: The History of the of the of the of the of the of the<|endoftext|>\n",
      "Ep 1 (Step 000035): Train loss 1.859, Val loss 2.003\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The sentence 'The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000040): Train loss 1.780, Val loss 1.955\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The '' is '.'<|endoftext|>: The of the is the of the<|endoftext|>: The of the is the<|endoftext|>: The of the is the<|endoftext|>: The of the<|endoftext|>: The of the<|endoftext|>: The of the<|endoftext|>: The\n",
      "Ep 1 (Step 000045): Train loss 1.587, Val loss 1.908\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the<|endoftext|>: The Role of the in in in the sentence ' the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000050): Train loss 1.880, Val loss 1.846\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the the the the the<|endoftext|>: The of the the the the the the the the the the the the the the the the the<|endoftext|>: The of the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000055): Train loss 1.846, Val loss 1.807\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000060): Train loss 1.765, Val loss 1.752\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The: the the the<|endoftext|>: The of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000065): Train loss 1.607, Val loss 1.722\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000070): Train loss 1.422, Val loss 1.693\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000075): Train loss 1.389, Val loss 1.699\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000080): Train loss 1.508, Val loss 1.649\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000085): Train loss 1.467, Val loss 1.606\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000090): Train loss 1.567, Val loss 1.599\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000095): Train loss 1.205, Val loss 1.562\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000100): Train loss 1.349, Val loss 1.559\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 1 (Step 000105): Train loss 1.490, Val loss 1.557\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the the the the the the the the the the the the<|endoftext|>The following is instruction describes task Write response appropriately the. ###:The is a. ###:The is. ###\n",
      "Ep 1 (Step 000110): Train loss 1.542, Val loss 1.539\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the. ###:The is<|endoftext|>: The of the<|endoftext|>: The of the<|endoftext|>: The of the<|endoftext|>: The of the the of the<|endoftext|>: The of the the of the<|endoftext|>: The of the\n",
      "Ep 1 (Step 000115): Train loss 1.297, Val loss 1.514\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is '.'<|endoftext|>The following is instruction describes task Write response appropriately ###:The of is ###:The<|endoftext|>: The of is ###:The of is<|endoftext|>: The of is ###:The of is \n",
      "Ep 2 (Step 000120): Train loss 1.222, Val loss 1.512\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is ' every ' ' meal<|endoftext|>The following is instruction describes task Write response appropriately the. ###:The is ''<|endoftext|>: The of is is is is is is is is is is is is is is is is is\n",
      "Ep 2 (Step 000125): Train loss 1.207, Val loss 1.522\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the the<|endoftext|>: The of the is the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000130): Train loss 1.105, Val loss 1.500\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the.<|endoftext|>: The is the. ###:The the.###:<|endoftext|>: The is the###:<|endoftext|>: The is the###: ###: ###: ###: ###: ###:\n",
      "Ep 2 (Step 000135): Train loss 1.192, Val loss 1.488\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is sentence passive '' '' the meal<|endoftext|>: The is the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000140): Train loss 1.169, Val loss 1.493\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is sentence passive ' the meal day<|endoftext|>: The is the of the<|endoftext|>: The of the<|endoftext|>: The of the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000145): Train loss 1.029, Val loss 1.484\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the. ###:The is of<|endoftext|>: The is ###:The is ###:The ###:The ###:The ###:The ###:The<|endoftext|>: The of the is\n",
      "Ep 2 (Step 000150): Train loss 1.084, Val loss 1.469\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the<|endoftext|>: The is the of the<|endoftext|>: The of the<|endoftext|>: The of the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000155): Train loss 1.168, Val loss 1.437\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the the the the the the the the the the the the the the the the the the<|endoftext|>: The of the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000160): Train loss 1.069, Val loss 1.427\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the by the. ###:The by the<|endoftext|>: The of the is the. is the<|endoftext|>: The of the is<|endoftext|>: The of the is<|endoftext|>: The of the is the. : The the the\n",
      "Ep 2 (Step 000165): Train loss 1.077, Val loss 1.426\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the day ###:The the the the<|endoftext|>: The of the is the of<|endoftext|>: The of the is the<|endoftext|>: The of the is the of the<|endoftext|>: The of the the the the the the\n",
      "Ep 2 (Step 000170): Train loss 0.842, Val loss 1.412\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the<|endoftext|>The following is instruction describes task Write response appropriately the by '.'<|endoftext|>: The of the is the of the of the<|endoftext|>: The of the of the of the of the of the of the<|endoftext|>:\n",
      "Ep 2 (Step 000175): Train loss 0.928, Val loss 1.390\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the. day<|endoftext|>The following is instruction describes task Write response appropriately the. ' the a the<|endoftext|>: The of is '.' '.' '.'<|endoftext|>: The of is '.' '.'<|endoftext|>: The of\n",
      "Ep 2 (Step 000180): Train loss 1.034, Val loss 1.389\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the. day the meal ###:The is the. ###:The is meal<|endoftext|>The following is instruction describes task Write response appropriately the. ###:What the of? ###:The of is. \n",
      "Ep 2 (Step 000185): Train loss 1.104, Val loss 1.389\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the every the? ###:The is meal<|endoftext|>The following is instruction describes task Write response appropriately the. ###:What the of of of? ###:The of is.<|endoftext|>: The of is<|endoftext|>:\n",
      "Ep 2 (Step 000190): Train loss 0.818, Val loss 1.374\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the every<|endoftext|>The following is instruction describes task Write response appropriately the. ###:The is the every<|endoftext|>: The of is the of of of of<|endoftext|>: The of is of of : the : the the\n",
      "Ep 2 (Step 000195): Train loss 1.064, Val loss 1.364\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the. the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000200): Train loss 0.812, Val loss 1.330\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is meal every. ###:The is. day<|endoftext|>The following is instruction describes task Write response appropriately ###:What the of the of? ###:The of is.<|endoftext|>: The of is. ###:\n",
      "Ep 2 (Step 000205): Train loss 0.918, Val loss 1.335\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is meal every. ###:The the every. ###:The the meal day<|endoftext|>The following is instruction describes task Write response appropriately ###:Rew the sentence the is. ###:The is. ###:\n",
      "Ep 2 (Step 000210): Train loss 1.133, Val loss 1.323\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the every. ###:The the meal day ###:The the every<|endoftext|>The following is instruction describes task Write response appropriately ###:Rew the sentence the is the ###:The the the ###:The\n",
      "Ep 2 (Step 000215): Train loss 1.012, Val loss 1.328\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the every the. ###:The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000220): Train loss 0.789, Val loss 1.337\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The the the the the the the the ###:The the the the the the<|endoftext|>The following is instruction describes task Write response appropriately ###:Con the the the the###:The the the the###: the the###:\n",
      "Ep 2 (Step 000225): Train loss 0.954, Val loss 1.361\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The is the of the of the? ###:The is of meal<|endoftext|>The following is instruction describes task Write response appropriately ###:Gener a that the of the ###:The of is. ###:The is of\n",
      "Ep 2 (Step 000230): Train loss 0.796, Val loss 1.334\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.' ###:The chef the meal every. ###:The the meal<|endoftext|>The following is instruction describes task Write response appropriately ###:Rew the sentence the it the the the the the the the the the the the the the the the the the\n",
      "Training completed in 71.78 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Instruction fine-tuning the pretrained LLM\n",
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> ###:The of Pride and Prejud is. by.\n",
      "###:The of is. by.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "        )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    \n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "print(input_text)\n",
    "print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [14:40<00:00,  8.01s/it] \n"
     ]
    }
   ],
   "source": [
    "# Generating test set responses\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "        )\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    "    )\n",
    "test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The instruction-fine-tuning process adapts a pretrained LLM to follow human instructions and generate desired responses.\n",
    "\n",
    "- **Dataset Preparation**  \n",
    "  Preparing the dataset involves downloading an instruction-response dataset, formatting the entries, and splitting it into train, validation, and test sets.\n",
    "\n",
    "- **Batch Construction**  \n",
    "  Training batches are constructed using a custom collate function that pads sequences, creates target token IDs, and masks padding tokens.\n",
    "\n",
    "- **Model Initialization**  \n",
    "  We load a pretrained GPT-2 medium model with 355 million parameters to serve as the starting point for instruction fine-tuning.\n",
    "\n",
    "- **Fine-Tuning Process**  \n",
    "  The pretrained model is fine-tuned on the instruction dataset using a training loop similar to pretraining.\n",
    "\n",
    "- **Evaluation**  \n",
    "  Evaluation involves extracting model responses on a test set and scoring them (for example, using another LLM).\n",
    "\n",
    "- **Scoring with Ollama**  \n",
    "  The Ollama application with an 8-billion-parameter Llama model can be used to automatically score the fine-tuned modelâ€™s responses on the test set, providing an average score to quantify performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
