{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a GPT model from scratch to generate text\n",
    "\n",
    "\n",
    "* Coding a GPT-like large language model (LLM)\n",
    "that can be trained to generate human-like text\n",
    "* Normalizing layer activations to stabilize neural\n",
    "network training\n",
    "* Adding shortcut connections in deep neural\n",
    "networks\n",
    "* Implementing transformer blocks to create GPT\n",
    "models of various sizes\n",
    "* Computing the number of parameters and\n",
    "storage requirements of GPT models\n",
    "* 12 transformers block in GPT2 124M\n",
    "* To put the scale of our project into perspective, consider the training of the 7 billion parameter Llama 2 model, a relatively popular openly available LLM. This model required 184,320 GPU hours on expensive A100 GPUs, processing 2 trillion tokens. At the time of writing, running an 8 × A100 cloud server on AWS costs around $30 per hour. A rough estimate puts the total training cost of such an LLM at around $690,000 (calculated as 184,320 hours divided by 8, then multiplied by $30)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... it would take 355 years to train GPT-3 (175 billion) on a single V100 datacenter GPU\n",
    "and 665 years on a consumer RTX 8000 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257, # Vocabulary size\n",
    "\"context_length\": 1024, # Context length\n",
    "\"emb_dim\": 768, # Embedding dimension\n",
    "\"n_heads\": 12, # Number of attention heads\n",
    "\"n_layers\": 12, # Number of layers\n",
    "\"drop_rate\": 0.1, # Dropout rate\n",
    "\"qkv_bias\": False # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        \n",
    "        self.final_norm = DummyLayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "        torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "batch = []\n",
    "txt1 = 'Every effort moves you'\n",
    "txt2 = 'Every day holds a'\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model 124M\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing activations with layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.4091, 0.6587, 0.3914, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1902, 0.3182, 0.6486, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_sample = torch.rand(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_sample)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[0.2432],\n",
      "        [0.1928]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[0.0799],\n",
      "        [0.0670]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print('Mean: \\n', mean)\n",
    "print('Variance: \\n', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs: \n",
      " tensor([[-0.8603, -0.8603,  0.5869,  1.4698,  0.5242, -0.8603],\n",
      "        [-0.7450, -0.7450, -0.0102,  0.4844,  1.7608, -0.7450]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[0.0000e+00],\n",
      "        [9.9341e-09]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print('Normalized layer outputs: \\n', out_norm)\n",
    "print('Mean:\\n', mean)\n",
    "print('Variance:\\n', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print('Mean:\\n', mean)\n",
    "print('Variance:\\n', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer normalization class \n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[     0.0000],\n",
      "        [    -0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.9998],\n",
      "        [0.9999]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_sample)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing a feed forward network with GELU activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELU activation function\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward nn module\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], cfg['emb_dim'] * 4),\n",
    "            GELU(),\n",
    "            nn.Linear(cfg['emb_dim'] * 4, cfg['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shortcut Connection (Skip or Residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN to illustrate shortcut connections\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),\n",
    "                          GELU())\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss = loss_fn(output, target)\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name and param.grad is not None:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explanation of the Results\\n\\nThe results show how **shortcut connections** (or their absence) affect the gradients during training.\\n\\nResults without shortcut (model without shortcut):\\n- The gradients for the layer weights are **smaller** with minimal variance across layers. \\n- This suggests that the model updates weights more slowly and in a more stable manner, which is typical for standard neural networks without shortcut connections.\\n\\nResults with shortcut (model with shortcut):\\n- The gradients are significantly **larger**, ranging from 0.2 to 1.3 for different layers.\\n- This is because **shortcut connections** allow for **easier information flow** between layers, enhancing the **trainability** of the model.\\n- Larger gradients help the network update weights faster, especially in deep networks.\\n\\nConclusion:\\n- **Without shortcut:** Smaller gradients, possibly slower learning.\\n- **With shortcut:** Larger gradients, leading to faster training and better information flow in deep networks.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Explanation of the Results\n",
    "\n",
    "The results show how **shortcut connections** (or their absence) affect the gradients during training.\n",
    "\n",
    "Results without shortcut (model without shortcut):\n",
    "- The gradients for the layer weights are **smaller** with minimal variance across layers. \n",
    "- This suggests that the model updates weights more slowly and in a more stable manner, which is typical for standard neural networks without shortcut connections.\n",
    "\n",
    "Results with shortcut (model with shortcut):\n",
    "- The gradients are significantly **larger**, ranging from 0.2 to 1.3 for different layers.\n",
    "- This is because **shortcut connections** allow for **easier information flow** between layers, enhancing the **trainability** of the model.\n",
    "- Larger gradients help the network update weights faster, especially in deep networks.\n",
    "\n",
    "Conclusion:\n",
    "- **Without shortcut:** Smaller gradients, possibly slower learning.\n",
    "- **With shortcut:** Larger gradients, leading to faster training and better information flow in deep networks.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connecting attention and linear layers in a transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements multi-head self-attention efficiently. \n",
    "    Instead of processing each attention head separately, it uses a single large weight matrix \n",
    "    and splits the outputs into multiple heads. This allows for parallel computation, \n",
    "    improving speed and reducing memory usage.\n",
    "\n",
    "    Key features:\n",
    "    - Uses a single set of weights for query, key, and value projections.\n",
    "    - Splits the projected values into multiple attention heads.\n",
    "    - Applies causal masking to prevent information leakage from future tokens.\n",
    "    - Computes attention in parallel across all heads.\n",
    "    - Uses an output projection layer to merge information from all heads.\n",
    "\n",
    "    This implementation is more efficient than stacking multiple single-head attention layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_in, d_out, \n",
    "                 context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            'd_out must be divisible by num_heads'\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.d_head)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.d_head)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.d_head)\n",
    "\n",
    "\n",
    "        \n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        \n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer block component of GPT\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias'])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 5, 768])\n",
      "Output shape: torch.Size([2, 5, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 5, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coding the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "vocabulary size of the tokenizer: 50257\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)\n",
    "print(f'vocabulary size of the tokenizer: {50257}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "# number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "# trainable parameters\n",
    "total_params_gpt2 = (\n",
    "total_params - sum(p.numel()\n",
    "for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of trainable parameters \"\n",
    "f\"considering weight tying: {total_params_gpt2:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# model size\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates a simple implementation of a generative loop for a lan-\n",
    "guage model using PyTorch. It iterates for a specified number of new tokens to be\n",
    "generated, crops the current context to fit the model’s maximum context size, com-\n",
    "putes predictions, and then selects the next token based on the highest probability\n",
    "prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    '''\n",
    "    Generates text using a GPT model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The GPT model.\n",
    "    - idx: The current token sequence (batch, n_tokens).\n",
    "    - max_new_tokens: Number of new tokens to generate.\n",
    "    - context_size: Maximum number of tokens used as context.\n",
    "\n",
    "    Returns:\n",
    "    - Updated idx with newly generated tokens.\n",
    "    '''\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Keep only the last context_size tokens\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)  # Get model predictions\n",
    "\n",
    "        logits = logits[:, -1, :]  # Focus on the last time step\n",
    "        probas = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # Select the most probable token\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # Append the new token\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n",
      "\n",
      "! The model is unable to produce coherent text is that we haven’t trained it yet.\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text + \"\\n\")\n",
    "print('! The model is unable to produce coherent text is that we haven’t trained it yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Layer normalization** stabilizes training by ensuring that each layer’s outputs have a consistent mean and variance.  \n",
    "- **Shortcut connections** skip one or more layers, allowing outputs to be fed directly to deeper layers. This helps mitigate the **vanishing gradient problem**, especially in deep neural networks like LLMs.  \n",
    "- **Transformer blocks** are the core of GPT models, combining **masked multi-head attention** with **fully connected feed-forward networks** that use the **GELU activation function**.  \n",
    "- **GPT models** are LLMs composed of multiple **repeated transformer blocks**, containing **millions to billions of parameters**.  \n",
    "- **GPT models come in different sizes**, such as **124M, 345M, 762M, and 1,542M parameters**, all of which can be implemented using the same `GPTModel` Python class.  \n",
    "- **Text generation in GPT models** involves decoding output tensors into human-readable text by **predicting one token at a time** based on a given input context.  \n",
    "- **Without training, a GPT model generates incoherent text**, highlighting the necessity of training for coherent text generation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256,  # original: 1024\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Converts a text string into a tensor of token IDs using the specified tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    - text: The input string to tokenize.\n",
    "    - tokenizer: The tokenizer used to encode the text.\n",
    "\n",
    "    Returns:\n",
    "    - A PyTorch tensor containing the token IDs with an added batch dimension.\n",
    "    \"\"\"\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    \"\"\"\n",
    "    Converts a tensor of token IDs back into a human-readable text string.\n",
    "\n",
    "    Parameters:\n",
    "    - token_ids: A tensor containing token IDs.\n",
    "    - tokenizer: The tokenizer used to decode the token IDs.\n",
    "\n",
    "    Returns:\n",
    "    - A decoded text string.\n",
    "    \"\"\"\n",
    "    flat = token_ids.squeeze(0)  # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# Define the initial text input\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Generate new token IDs using the GPT model\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# Convert generated token IDs back to text and print\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],  # [\"every effort moves\",\n",
    "                          [40, 1107, 588]])  # \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                       [1107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print('Characters:', total_characters)\n",
    "print('Tokens:', total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class GPTDatasetV1:\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokens = tokenizer.encode(txt)\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        self.samples = self._create_samples()\n",
    "\n",
    "    def _create_samples(self):\n",
    "        samples = []\n",
    "        for i in range(0, len(self.tokens) - self.max_length, self.stride):\n",
    "            input_tokens = self.tokens[i:i + self.max_length]\n",
    "            target_tokens = self.tokens[i + 1:i + self.max_length + 1]\n",
    "            samples.append((input_tokens, target_tokens))  # Возвращаем кортеж (входные данные, цель)\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_tokens, target_tokens = self.samples[idx]\n",
    "        return torch.tensor(input_tokens, dtype=torch.long), torch.tensor(target_tokens, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)  # Разбиваем batch на входные данные и цели\n",
    "    inputs = torch.stack(inputs)  # Превращаем в батч тензоров\n",
    "    targets = torch.stack(targets)\n",
    "    return inputs, targets\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")  # Инициализация токенизатора\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)  # Создание датасета\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn  # Добавляем collate_fn для преобразования в тензоры\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583690219456\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Process in PyTorch\n",
    "\n",
    "1. **Loop over epochs** – Full pass through the dataset.\n",
    "2. **Loop over batches** – Split data into mini-batches.\n",
    "3. **Zero gradients** – Reset gradients to prevent accumulation:\n",
    "   ```python\n",
    "   optimizer.zero_grad()\n",
    "   ```\n",
    "4. **Compute loss** – Forward pass and loss calculation:\n",
    "   ```python\n",
    "   outputs = model(input_batch)\n",
    "   loss = loss_function(outputs, target_batch)\n",
    "   ```\n",
    "5. **Backpropagation** – Compute gradients:\n",
    "   ```python\n",
    "   loss.backward()\n",
    "   ```\n",
    "6. **Update weights** – Adjust model parameters:\n",
    "   ```python\n",
    "   optimizer.step()\n",
    "   ```\n",
    "7. **Print losses** – Monitor training and validation loss.\n",
    "8. **Generate text (optional)** – Inspect model output:\n",
    "   ```python\n",
    "   sample_text = generate_text(model, tokenizer, prompt=\"AI is\")\n",
    "   print(sample_text)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main function for pretraining LLMs\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                        eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    for epoch in range(num_epochs):  # Main training loop\n",
    "        model.train()  \n",
    "        \n",
    "        for input_batch, target_batch in train_loader:  # Iterate over batches\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update model weights\n",
    "\n",
    "            tokens_seen += input_batch.numel()  # Track number of processed tokens\n",
    "            global_step += 1  \n",
    "\n",
    "            if global_step % eval_freq == 0:  # Evaluate model at specified intervals\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                \n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "                generate_and_print_sample(model, tokenizer, device, start_context)  # Generate sample text\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # Set the model to evaluation mode (disables dropout, batch norm updates)\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation to save memory and speed up evaluation\n",
    "        train_loss = calc_loss_loader(train_loader, model, device,      num_batches=eval_iter)  # Compute train loss\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)  # Compute validation loss\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return train_loss, val_loss  # Return computed losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, batch norm updates)\n",
    "\n",
    "    context_size = model.pos_emb.weight.shape[0]  # Get the context size from positional embeddings\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)  # Encode input text and move to device\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking for efficiency\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, \n",
    "            max_new_tokens=50, context_size=context_size  # Generate up to 50 new tokens\n",
    "        )\n",
    "\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)  # Convert token IDs back to text\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Print output with newlines replaced for readability\n",
    "\n",
    "    model.train()  # Switch model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.783, Val loss 9.927\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 1 (Step 000005): Train loss 7.985, Val loss 8.335\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000010): Train loss 6.753, Val loss 7.048\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000015): Train loss 6.114, Val loss 6.573\n",
      "Every effort moves you, the to the to the.                                           \n",
      "Ep 3 (Step 000020): Train loss 5.525, Val loss 6.490\n",
      "Every effort moves you, and, and the of the of the of the of the of the of the of the of the of the of the of the of the the of the the of the of the of the of the of the of the of the of the of\n",
      "Ep 3 (Step 000025): Train loss 5.324, Val loss 6.387\n",
      "Every effort moves you his \" to the picture.  \"I, and I had been, and, and I had been, and I had been, and I had the his--I, and I had been, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 4.761, Val loss 6.360\n",
      "Every effort moves you of the to the picture.                      \"I\"I me his\"I my\"I\"I\"I and my\"I\"I me\n",
      "Ep 4 (Step 000035): Train loss 4.461, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.833, Val loss 6.196\n",
      "Every effort moves you, as,,,,,,, as,, as.                      \"--and it's the,,,,,,,,\n",
      "Ep 6 (Step 000045): Train loss 3.352, Val loss 6.139\n",
      "Every effort moves you know it was not to the picture--I he was a little the last word.     \"I, and. \"I, and I had been at my dear and I felt a little a little of the picture. \n",
      "Ep 6 (Step 000050): Train loss 2.861, Val loss 6.112\n",
      "Every effort moves you know the fact, and I felt he was to the fact had the last word. Gisburn's an!                           \n",
      "Ep 7 (Step 000055): Train loss 2.347, Val loss 6.138\n",
      "Every effort moves you know it was not that, and he was--I had a little of a little: \"Yes, and up, I had been to the donkey, I had always to have him. \"--and, and down, and he was his\n",
      "Ep 7 (Step 000060): Train loss 2.084, Val loss 6.179\n",
      "Every effort moves you know,\" was not that, on the picture--I told Mrs.                                    \n",
      "Ep 8 (Step 000065): Train loss 1.521, Val loss 6.176\n",
      "Every effort moves you know,\" was one of the picture for nothing--I had a little of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"There were, I had\n",
      "Ep 8 (Step 000070): Train loss 1.272, Val loss 6.178\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, and. Gisburn, and I had been at my elbow and as I had been the \"strongest,\" she was\n",
      "Ep 9 (Step 000075): Train loss 1.000, Val loss 6.277\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, the moment--as Jack himself, my elbow and as I turned, my eye fell on a small picture\n",
      "Ep 9 (Step 000080): Train loss 0.718, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.506, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # Set random seed for reproducibility\n",
    "model = GPTModel(GPT_CONFIG_124M)  # Initialize the model with the given configuration\n",
    "model.to(device)  # Move the model to the appropriate device (CPU or GPU)\n",
    "\n",
    "# Initialize the optimizer (AdamW with learning rate and weight decay)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004,  # Learning rate\n",
    "    weight_decay=0.1  # Weight decay (L2 regularization)\n",
    ")\n",
    "\n",
    "num_epochs = 10  # Number of epochs for training\n",
    "\n",
    "# Train the model using the simple training loop\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,  # Model, data loaders, optimizer, device\n",
    "    num_epochs=num_epochs,  # Number of epochs\n",
    "    eval_freq=5,  # Frequency of evaluation during training (every 5 steps)\n",
    "    eval_iter=5,  # Number of iterations for evaluation\n",
    "    start_context=\"Every effort moves you\",  # Initial text for text generation during evaluation\n",
    "    tokenizer=tokenizer  # Tokenizer used for processing text\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Function to plot training and validation losses\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    # Create a figure and axis for plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot the training and validation losses against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    \n",
    "    # Set the x and y axis labels\n",
    "    ax1.set_xlabel(\"Epochs\")  # X-axis label for epochs\n",
    "    ax1.set_ylabel(\"Loss\")  # Y-axis label for loss\n",
    "\n",
    "    # Display a legend for the plot\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    \n",
    "    # Ensure that the x-axis ticks are integer values\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # Create a second x-axis (top) for tokens seen\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    # Plot an invisible line to link the top x-axis (tokens_seen) to the training losses\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # alpha=0 makes the line invisible\n",
    "\n",
    "    # Set the label for the second x-axis (tokens seen)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    # Automatically adjust the layout to avoid overlapping labels and elements\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Create a tensor for epochs ranging from 0 to num_epochs with the same length as train_losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "\n",
    "# Call the plot_losses function to plot the training and validation losses\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting training and validation loss plot is shown in figure 5.12. As we can see, both the training and validation losses start to improve for the first epoch. However, the losses start to diverge past the second epoch. This divergence and the fact that the validation loss is much larger than the training loss indicate that the model is overfitting to the training data. We can confirm that the model memorizes the training data verbatim by searching for the generated text snippets, such as quite insensible to the irony in the “The Verdict” text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")  # Move the model to CPU\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")  # Initialize the tokenizer\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "    for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "                 for T in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([2.0000, 1.0000, 0.5000])\n",
      "Top positions: tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "\n",
    "# Ensure next_token_logits is a tensor\n",
    "if isinstance(next_token_logits, list):\n",
    "    next_token_logits = torch.tensor(next_token_logits)\n",
    "\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified logits: tensor([2.0000, 1.0000, 0.5000,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where values lower than the smallest top-k logit are set to -inf\n",
    "new_logits = torch.where(\n",
    "    next_token_logits < top_logits[-1],  # Condition: if value < smallest top-k logit\n",
    "    torch.full_like(next_token_logits, float('-inf')),  # Assign -inf\n",
    "    next_token_logits  # Otherwise, keep original value\n",
    ")\n",
    "\n",
    "print(\"Modified logits:\", new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6285, 0.2312, 0.1402, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Limit the context to the last tokens\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)  # Get model predictions\n",
    "            logits = logits[:, -1, :]  # Focus on the last timestep logits\n",
    "        \n",
    "        # Apply top-k filtering\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, \n",
    "                                 torch.full_like(logits, float('-inf')), \n",
    "                                 logits)\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # Sample from probabilities\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # Greedy selection\n",
    "        \n",
    "        # Stop generation if end-of-sequence token is reached\n",
    "        if eos_id is not None and (idx_next == eos_id).all():\n",
    "            break\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # Append the new token to the sequence\n",
    "    \n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
